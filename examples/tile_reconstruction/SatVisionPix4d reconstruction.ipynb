{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07079c64-af33-4833-b8ea-9238ab8edaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sys.path.append('/explore/nobackup/people/jacaraba/development/satvision-pix4d')\n",
    "\n",
    "from satvision_pix4d.configs.config import _C, _update_config_from_file\n",
    "from satvision_pix4d.pipelines import PIPELINES, get_available_pipelines\n",
    "from satvision_pix4d.datasets.abi_temporal_benchmark_dataset import ABITemporalBenchmarkDataset\n",
    "from satvision_pix4d.datasets.abi_temporal_dataset import ABITemporalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5036c029-0a45-4001-87b0-bcbf383f91a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whether to save files to a PDF, and where to save them \n",
    "save_to_pdf = False\n",
    "pdf_path = \"chip_plot.pdf\"\n",
    "\n",
    "# RGB indices for ABI data (16 channels instead of 14)\n",
    "rgb_index = [0, 2, 1]  # Adjust based on your ABI channels\n",
    "\n",
    "# Use your local model paths instead of downloading\n",
    "model_filename = '/explore/nobackup/projects/pix4dcloud/jacaraba/model_development/satmae/' + \\\n",
    "    'satmae_satvision_pix4d_pretrain-dev/satmae_satvision_pix4d_pretrain-dev/best-epoch=373-val_loss=36.2750.ckpt/checkpoint/mp_rank_00_model_states.pt'\n",
    "\n",
    "config_filename = '/explore/nobackup/people/jacaraba/development/satvision-pix4d/tests/configs/test_satmae_dev.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22d97d-0564-4e26-b357-8f16e068f4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config = _C.clone()\n",
    "_update_config_from_file(config, config_filename)\n",
    "print(\"Loaded configuration file.\")\n",
    "\n",
    "# Update config with your paths\n",
    "config.defrost()\n",
    "config.MODEL.PRETRAINED = model_filename\n",
    "config.DATA.DATA_PATHS = ['/explore/nobackup/people/jacaraba/projects/SatVision-Pix4d/tiles_pix4d/']\n",
    "config.OUTPUT = '.'\n",
    "config.freeze()\n",
    "print(\"Updated configuration file.\")\n",
    "\n",
    "# Get pipeline and load model\n",
    "available_pipelines = get_available_pipelines()\n",
    "print(\"Available pipelines:\", available_pipelines)\n",
    "\n",
    "pipeline = PIPELINES[config.PIPELINE]\n",
    "print(f'Using {pipeline}')\n",
    "\n",
    "ptlPipeline = pipeline(config)\n",
    "\n",
    "# Load model\n",
    "print(f'Attempting to load checkpoint from {config.MODEL.PRETRAINED}')\n",
    "model = ptlPipeline.load_checkpoint(config.MODEL.PRETRAINED, config)\n",
    "print('Successfully applied checkpoint')\n",
    "\n",
    "model.cpu()\n",
    "model.eval()\n",
    "print('Successfully moved to CPU and eval mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab43139-25dc-44c2-aef2-9d23f617c0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "data_dir = '/explore/nobackup/people/jacaraba/projects/SatVision-Pix4d/tiles_pix4d/'\n",
    "\n",
    "all_zarr_files = [f for f in os.listdir(data_dir) if f.endswith('.zarr')]\n",
    "print(f\"Found {len(all_zarr_files)} zarr files in directory\")\n",
    "\n",
    "train_ds = ABITemporalDataset(\n",
    "    data_paths=[data_dir], \n",
    "    img_size=512,\n",
    "    in_chans=16,\n",
    "    data_var='Rad'\n",
    ")\n",
    "\n",
    "print(f\"Dataset contains {len(train_ds)} samples from all files\")\n",
    "\n",
    "# Process multiple samples from the dataset\n",
    "num_samples = min(5, len(train_ds))  \n",
    "print(f\"Processing {num_samples} samples from multiple files...\")\n",
    "\n",
    "all_inputs = []\n",
    "all_outputs = []\n",
    "all_masks = []\n",
    "all_losses = []\n",
    "\n",
    "print(f\"\\nProcessing samples for reconstruction...\")\n",
    "for sample_idx in tqdm(range(num_samples)):\n",
    "    try:\n",
    "        imgs, ts = train_ds[sample_idx]\n",
    "        \n",
    "        # NO NORMALIZATION\n",
    "        imgs_batch = imgs.unsqueeze(0).cpu()\n",
    "        if isinstance(ts, np.ndarray):\n",
    "            ts = torch.from_numpy(ts).float()\n",
    "        ts_batch = ts.unsqueeze(0).cpu()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss, pred, mask = model(imgs_batch, ts_batch)\n",
    "            \n",
    "            B, T, C, H, W = imgs_batch.shape\n",
    "            pred_imgs = model.model.unpatchify(pred, T, H, W)\n",
    "            pred_imgs = torch.clamp(pred_imgs, 0, 1)\n",
    "        \n",
    "        # Store results\n",
    "        all_inputs.append(imgs_batch.cpu().squeeze(0))\n",
    "        all_outputs.append(pred_imgs.cpu().squeeze(0))\n",
    "        all_masks.append(mask.cpu().squeeze(0))\n",
    "        all_losses.append(loss.cpu().item())\n",
    "        \n",
    "        if sample_idx % 10 == 0:  # Print progress every 10 samples\n",
    "            print(f\"Sample {sample_idx}: Loss = {loss.item():.2f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing sample {sample_idx}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n=== FINAL RESULTS ===\")\n",
    "print(f\"Total samples processed: {len(all_inputs)}\")\n",
    "print(f\"Average loss across all samples: {np.mean(all_losses):.4f}\")\n",
    "\n",
    "# Update global variables for compatibility with existing code\n",
    "inputs = all_inputs\n",
    "outputs = all_outputs\n",
    "masks = all_masks\n",
    "losses = all_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d2eaac-462a-4306-ab68-91c73261ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "\n",
    "def calculate_mse(original, reconstructed):\n",
    "    return torch.mean((original - reconstructed) ** 2).item()\n",
    "\n",
    "def calculate_psnr(mse, data_range=1.0):\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "def calculate_mae(original, reconstructed):\n",
    "    return torch.mean(torch.abs(original - reconstructed)).item()\n",
    "\n",
    "def calculate_ssim_fast(original, reconstructed, sample_channels=4):\n",
    "    \"\"\"Fast SSIM - only sample a few channels to speed up calculation\"\"\"\n",
    "    if isinstance(original, torch.Tensor):\n",
    "        original = original.numpy()\n",
    "    if isinstance(reconstructed, torch.Tensor):\n",
    "        reconstructed = reconstructed.numpy()\n",
    "    \n",
    "    ssim_scores = []\n",
    "    \n",
    "    #sample\n",
    "    total_channels = original.shape[0] * original.shape[1]  # T * C\n",
    "    channel_indices = np.linspace(0, total_channels-1, sample_channels, dtype=int)\n",
    "    \n",
    "    for idx in channel_indices:\n",
    "        t_idx = idx // original.shape[1]  # timestep\n",
    "        c_idx = idx % original.shape[1]   # channel\n",
    "        \n",
    "        if t_idx < original.shape[0] and c_idx < original.shape[1]:\n",
    "            try:\n",
    "                score = ssim(original[t_idx, c_idx], reconstructed[t_idx, c_idx], \n",
    "                           data_range=1.0)\n",
    "                ssim_scores.append(score)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    return np.mean(ssim_scores) if ssim_scores else 0.0\n",
    "\n",
    "\n",
    "print(\"Calculating comprehensive metrics for large dataset...\")\n",
    "print(f\"Processing {len(inputs)} samples...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "\n",
    "metrics_results = []\n",
    "batch_size = 20  \n",
    "\n",
    "# Process in batches\n",
    "for batch_start in range(0, len(inputs), batch_size):\n",
    "    batch_end = min(batch_start + batch_size, len(inputs))\n",
    "    batch_indices = range(batch_start, batch_end)\n",
    "    \n",
    "    print(f\"Processing batch {batch_start//batch_size + 1}/{(len(inputs)-1)//batch_size + 1} \"\n",
    "          f\"(samples {batch_start}-{batch_end-1})\")\n",
    "    \n",
    "    batch_metrics = []\n",
    "    \n",
    "    for i in batch_indices:\n",
    "        original = inputs[i]\n",
    "        reconstructed = outputs[i]\n",
    "        \n",
    "        mse = calculate_mse(original, reconstructed)\n",
    "        mae = calculate_mae(original, reconstructed)\n",
    "        psnr = calculate_psnr(mse)\n",
    "        \n",
    "        ssim_score = calculate_ssim_fast(original, reconstructed, sample_channels=4)\n",
    "        \n",
    "        rgb_indices = [1, 0, 2]\n",
    "        rgb_metrics = {}\n",
    "        \n",
    "        for band_name, band_idx in zip(['red', 'green', 'blue'], rgb_indices):\n",
    "            if band_idx < original.shape[1]:\n",
    "                \n",
    "                orig_band = original[:, band_idx, :, :].mean(dim=0)\n",
    "                recon_band = reconstructed[:, band_idx, :, :].mean(dim=0)\n",
    "                \n",
    "                band_mse = calculate_mse(orig_band, recon_band)\n",
    "                band_psnr = calculate_psnr(band_mse)\n",
    "                \n",
    "                rgb_metrics[band_name] = {'mse': band_mse, 'psnr': band_psnr}\n",
    "        \n",
    "        sample_metrics = {\n",
    "            'sample_idx': i,\n",
    "            'loss': losses[i],\n",
    "            'mse': mse,\n",
    "            'mae': mae,\n",
    "            'psnr': psnr,\n",
    "            'ssim': ssim_score,\n",
    "            'rgb_metrics': rgb_metrics\n",
    "        }\n",
    "        \n",
    "        batch_metrics.append(sample_metrics)\n",
    "    \n",
    "    metrics_results.extend(batch_metrics)\n",
    "    \n",
    "    # Print batch summary\n",
    "    batch_mse = [m['mse'] for m in batch_metrics]\n",
    "    batch_psnr = [m['psnr'] for m in batch_metrics]\n",
    "    print(f\"  Batch avg MSE: {np.mean(batch_mse):.6f}, avg PSNR: {np.mean(batch_psnr):.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"LARGE DATASET METRICS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Overall statistics\n",
    "all_mse = [m['mse'] for m in metrics_results]\n",
    "all_mae = [m['mae'] for m in metrics_results]\n",
    "all_psnr = [m['psnr'] for m in metrics_results]\n",
    "all_ssim = [m['ssim'] for m in metrics_results]\n",
    "all_loss = [m['loss'] for m in metrics_results]\n",
    "\n",
    "print(f\"Dataset Statistics (n={len(metrics_results)} samples):\")\n",
    "print(f\"  MSE:  {np.mean(all_mse):.6f} ± {np.std(all_mse):.6f}\")\n",
    "print(f\"  MAE:  {np.mean(all_mae):.6f} ± {np.std(all_mae):.6f}\")\n",
    "print(f\"  PSNR: {np.mean(all_psnr):.2f} ± {np.std(all_psnr):.2f} dB\")\n",
    "print(f\"  SSIM: {np.mean(all_ssim):.4f} ± {np.std(all_ssim):.4f}\")\n",
    "print(f\"  Loss: {np.mean(all_loss):.2f} ± {np.std(all_loss):.2f}\")\n",
    "\n",
    "\n",
    "print(f\"\\nPerformance Distribution Analysis:\")\n",
    "percentiles = [10, 25, 50, 75, 90]\n",
    "mse_percentiles = np.percentile(all_mse, percentiles)\n",
    "psnr_percentiles = np.percentile(all_psnr, percentiles)\n",
    "\n",
    "print(f\"MSE Percentiles:\")\n",
    "for p, val in zip(percentiles, mse_percentiles):\n",
    "    print(f\"  {p}th: {val:.6f}\")\n",
    "\n",
    "print(f\"PSNR Percentiles:\")\n",
    "for p, val in zip(percentiles, psnr_percentiles):\n",
    "    print(f\"  {p}th: {val:.2f} dB\")\n",
    "\n",
    "\n",
    "mse_threshold_good = np.percentile(all_mse, 33)  # Bottom third\n",
    "mse_threshold_bad = np.percentile(all_mse, 67)   # Top third\n",
    "\n",
    "good_samples = [i for i, m in enumerate(all_mse) if m <= mse_threshold_good]\n",
    "medium_samples = [i for i, m in enumerate(all_mse) if mse_threshold_good < m <= mse_threshold_bad]\n",
    "bad_samples = [i for i, m in enumerate(all_mse) if m > mse_threshold_bad]\n",
    "\n",
    "print(f\"\\nPerformance Categories:\")\n",
    "print(f\"  Good samples (bottom 33%): {len(good_samples)} samples\")\n",
    "print(f\"    Avg MSE: {np.mean([all_mse[i] for i in good_samples]):.6f}\")\n",
    "print(f\"    Avg PSNR: {np.mean([all_psnr[i] for i in good_samples]):.2f} dB\")\n",
    "\n",
    "print(f\"  Medium samples (middle 33%): {len(medium_samples)} samples\")\n",
    "print(f\"    Avg MSE: {np.mean([all_mse[i] for i in medium_samples]):.6f}\")\n",
    "print(f\"    Avg PSNR: {np.mean([all_psnr[i] for i in medium_samples]):.2f} dB\")\n",
    "\n",
    "print(f\"  Bad samples (top 33%): {len(bad_samples)} samples\")\n",
    "print(f\"    Avg MSE: {np.mean([all_mse[i] for i in bad_samples]):.6f}\")\n",
    "print(f\"    Avg PSNR: {np.mean([all_psnr[i] for i in bad_samples]):.2f} dB\")\n",
    "\n",
    "\n",
    "print(f\"\\nRGB Band Performance Summary:\")\n",
    "for band_name in ['red', 'green', 'blue']:\n",
    "    band_mse = [m['rgb_metrics'][band_name]['mse'] for m in metrics_results \n",
    "                if band_name in m['rgb_metrics']]\n",
    "    band_psnr = [m['rgb_metrics'][band_name]['psnr'] for m in metrics_results \n",
    "                 if band_name in m['rgb_metrics']]\n",
    "    \n",
    "    if band_mse:\n",
    "        print(f\"  {band_name.capitalize()}: MSE={np.mean(band_mse):.6f}, PSNR={np.mean(band_psnr):.2f}dB\")\n",
    "\n",
    "# Best and worst samples\n",
    "best_idx = np.argmin(all_mse)\n",
    "worst_idx = np.argmax(all_mse)\n",
    "\n",
    "print(f\"\\nExtreme Samples:\")\n",
    "print(f\"  Best sample #{best_idx}: MSE={all_mse[best_idx]:.6f}, PSNR={all_psnr[best_idx]:.2f}dB\")\n",
    "print(f\"  Worst sample #{worst_idx}: MSE={all_mse[worst_idx]:.6f}, PSNR={all_psnr[worst_idx]:.2f}dB\")\n",
    "print(f\"  Performance range: {all_mse[worst_idx]/all_mse[best_idx]:.1f}x difference\")\n",
    "\n",
    "# Save results summary\n",
    "performance_categories = {\n",
    "    'good': good_samples,\n",
    "    'medium': medium_samples, \n",
    "    'bad': bad_samples\n",
    "}\n",
    "\n",
    "print(f\"\\nMetrics calculation complete!\")\n",
    "print(f\"Results stored in 'metrics_results' and 'performance_categories' variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295ddcaf-46e4-4fa2-a16d-3c02bdc7412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_reconstruction(inputs, outputs, sample_idx=0, timestep=0, rgb_index=[1, 0, 2]):\n",
    "    \"\"\"Visualize original vs reconstructed for ABI satellite data\"\"\"\n",
    "    \n",
    "    # Convert inputs and outputs to proper tensor format\n",
    "    if isinstance(inputs, list):\n",
    "        if len(inputs) > 0:\n",
    "            inputs_tensor = inputs[0] if torch.is_tensor(inputs[0]) else torch.tensor(inputs[0])\n",
    "        else:\n",
    "            print(\"No input data available\")\n",
    "            return\n",
    "    else:\n",
    "        inputs_tensor = inputs\n",
    "    \n",
    "    if isinstance(outputs, list):\n",
    "        if len(outputs) > 0:\n",
    "            outputs_tensor = outputs[0] if torch.is_tensor(outputs[0]) else torch.tensor(outputs[0])\n",
    "        else:\n",
    "            print(\"No output data available\")\n",
    "            return\n",
    "    else:\n",
    "        outputs_tensor = outputs\n",
    "    \n",
    "    print(f\"Inputs shape: {inputs_tensor.shape}\")\n",
    "    print(f\"Outputs shape: {outputs_tensor.shape}\")\n",
    "    \n",
    "    # FIX: Handle the specific tensor shapes correctly\n",
    "    if len(inputs_tensor.shape) == 4:  # [time, channels, height, width]\n",
    "        # This is your case - get all channels for a specific time\n",
    "        original = inputs_tensor[timestep]  # [16, 512, 512]\n",
    "    elif len(inputs_tensor.shape) == 5:  # [batch, time, channels, height, width]\n",
    "        original = inputs_tensor[sample_idx, timestep]  # [16, 512, 512]\n",
    "    else:\n",
    "        print(f\"Unexpected input shape: {inputs_tensor.shape}\")\n",
    "        return\n",
    "    \n",
    "    if len(outputs_tensor.shape) == 4:  # [time, channels, height, width]\n",
    "        reconstructed = outputs_tensor[timestep]  # [16, 512, 512]\n",
    "    elif len(outputs_tensor.shape) == 5:  # [batch, time, channels, height, width]\n",
    "        reconstructed = outputs_tensor[sample_idx, timestep]  # [16, 512, 512]\n",
    "    else:\n",
    "        print(f\"Unexpected output shape: {outputs_tensor.shape}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Data shapes - Original: {original.shape}, Reconstructed: {reconstructed.shape}\")\n",
    "    print(f\"Data ranges - Original: [{original.min():.3f}, {original.max():.3f}], \"\n",
    "          f\"Reconstructed: [{reconstructed.min():.3f}, {reconstructed.max():.3f}]\")\n",
    "    \n",
    "    # Move tensors to CPU\n",
    "    original = original.detach().cpu()\n",
    "    reconstructed = reconstructed.detach().cpu()\n",
    "    \n",
    "    # Create RGB images using specified bands\n",
    "    original_rgb = original[rgb_index].permute(1, 2, 0).numpy()  # (512, 512, 3)\n",
    "    reconstructed_rgb = reconstructed[rgb_index].permute(1, 2, 0).numpy()  # (512, 512, 3)\n",
    "    \n",
    "    # Rest of your function continues as before...\n",
    "    def normalize_abi_rgb(rgb_data):\n",
    "        \"\"\"Normalize ABI RGB data for better visualization\"\"\"\n",
    "        normalized = np.zeros_like(rgb_data)\n",
    "        for i in range(3):\n",
    "            channel = rgb_data[:, :, i]\n",
    "            p2, p98 = np.percentile(channel, [2, 98])\n",
    "            if p98 > p2:\n",
    "                normalized[:, :, i] = np.clip((channel - p2) / (p98 - p2), 0, 1)\n",
    "            else:\n",
    "                normalized[:, :, i] = 0\n",
    "        return normalized\n",
    "    \n",
    "    original_display = normalize_abi_rgb(original_rgb)\n",
    "    reconstructed_display = normalize_abi_rgb(reconstructed_rgb)\n",
    "    \n",
    "    diff = np.abs(original_display - reconstructed_display)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Top row: RGB composites\n",
    "    axes[0, 0].imshow(original_display)\n",
    "    axes[0, 0].set_title(f'Original RGB (Time {timestep})\\nBands {rgb_index}')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    axes[0, 1].imshow(reconstructed_display)\n",
    "    axes[0, 1].set_title(f'Reconstructed RGB\\nBands {rgb_index}')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    im_diff = axes[0, 2].imshow(diff, cmap='hot')\n",
    "    axes[0, 2].set_title(f'RGB Difference\\nMean: {np.mean(diff):.4f}')\n",
    "    axes[0, 2].axis('off')\n",
    "    plt.colorbar(im_diff, ax=axes[0, 2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    for i, (band_idx, color_name) in enumerate(zip(rgb_index, ['Red', 'Green', 'Blue'])):\n",
    "        orig_band = original[band_idx].numpy()\n",
    "        recon_band = reconstructed[band_idx].numpy()\n",
    "        \n",
    "        orig_p2, orig_p98 = np.percentile(orig_band, [2, 98])\n",
    "        recon_p2, recon_p98 = np.percentile(recon_band, [2, 98])\n",
    "        \n",
    "        if orig_p98 > orig_p2:\n",
    "            orig_norm = np.clip((orig_band - orig_p2) / (orig_p98 - orig_p2), 0, 1)\n",
    "        else:\n",
    "            orig_norm = np.zeros_like(orig_band)\n",
    "            \n",
    "        if recon_p98 > recon_p2:\n",
    "            recon_norm = np.clip((recon_band - recon_p2) / (recon_p98 - recon_p2), 0, 1)\n",
    "        else:\n",
    "            recon_norm = np.zeros_like(recon_band)\n",
    "        \n",
    "        band_diff = np.abs(orig_norm - recon_norm)\n",
    "        combined = np.hstack([orig_norm, recon_norm, band_diff])\n",
    "        \n",
    "        im = axes[1, i].imshow(combined, cmap='viridis')\n",
    "        axes[1, i].set_title(f'Band {band_idx} ({color_name})\\nOrig | Recon | Diff')\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        h, w = orig_norm.shape\n",
    "        axes[1, i].axvline(x=w-0.5, color='white', linewidth=2)\n",
    "        axes[1, i].axvline(x=2*w-0.5, color='white', linewidth=2)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    mse = np.mean((original.numpy() - reconstructed.numpy()) ** 2)\n",
    "    rgb_mse = np.mean((original_display - reconstructed_display) ** 2)\n",
    "    \n",
    "    print(f\"\\nQuantitative Metrics:\")\n",
    "    print(f\"  Overall MSE (all bands): {mse:.6f}\")\n",
    "    print(f\"  RGB MSE: {rgb_mse:.6f}\")\n",
    "    print(f\"  RGB Mean Abs Diff: {np.mean(diff):.4f}\")\n",
    "    print(f\"  RGB Max Abs Diff: {np.max(diff):.4f}\")\n",
    "    print(f\"  Pixels with >10% difference: {np.sum(diff > 0.1) / diff.size * 100:.1f}%\")\n",
    "\n",
    "# Call the function\n",
    "if 'pred_imgs' in locals() and 'imgs' in locals():\n",
    "    print(\"ABI Satellite Data Reconstruction Results:\")\n",
    "    print(\"=\"*50)\n",
    "    visualize_reconstruction(imgs, pred_imgs, sample_idx=0, timestep=0, rgb_index=[1, 0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa85aa33-72b5-4522-b35d-017180a2fb4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:soehrle-satvis_kernel]",
   "language": "python",
   "name": "conda-env-soehrle-satvis_kernel-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

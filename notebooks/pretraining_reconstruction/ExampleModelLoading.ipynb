{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004466c2-cd13-4065-8e65-3eae6c5880be",
   "metadata": {},
   "source": [
    "# Example Model Loading\n",
    "\n",
    "This notebook is an example for loading the pre-trained model. Given that this is just a test, you\n",
    "will only be able to load this model from Explore for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f9e8871-95d5-465e-a8fd-bc784594fd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pytorch-lightning\n",
      "  Downloading pytorch_lightning-2.5.2-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting torch>=2.1.0 (from pytorch-lightning)\n",
      "  Downloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from pytorch-lightning) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.4 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from pytorch-lightning) (6.0.2)\n",
      "Requirement already satisfied: fsspec>=2022.5.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2025.3.0)\n",
      "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
      "  Downloading torchmetrics-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from pytorch-lightning) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from pytorch-lightning) (4.12.2)\n",
      "Requirement already satisfied: lightning-utilities>=0.10.0 in /home/soehrle/.local/lib/python3.12/site-packages (from pytorch-lightning) (0.14.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.11.14)\n",
      "Requirement already satisfied: setuptools in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (75.8.2)\n",
      "Requirement already satisfied: filelock in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.18.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.5)\n",
      "Requirement already satisfied: jinja2 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in /home/soehrle/.local/lib/python3.12/site-packages (from torch>=2.1.0->pytorch-lightning) (3.3.1)\n",
      "Requirement already satisfied: numpy>1.20.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from torchmetrics>=0.7.0->pytorch-lightning) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.18.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/soehrle/.local/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.1.0->pytorch-lightning) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from jinja2->torch>=2.1.0->pytorch-lightning) (3.0.2)\n",
      "Requirement already satisfied: idna>=2.0 in /panfs/ccds02/app/modules/jupyter/lab/4.3.6/lib/python3.12/site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (3.10)\n",
      "Downloading pytorch_lightning-2.5.2-py3-none-any.whl (825 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.4/825.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.7.1-cp312-cp312-manylinux_2_28_x86_64.whl (821.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.0/821.0 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torchmetrics-1.8.0-py3-none-any.whl (981 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch, torchmetrics, pytorch-lightning\n",
      "\u001b[33m  WARNING: The scripts torchfrtrace and torchrun are installed in '/home/soehrle/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pytorch-lightning-2.5.2 torch-2.7.1 torchmetrics-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfb5a3ba-8f27-42d8-a5fe-c0fc066e684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 14:39:56,457] [WARNING] [real_accelerator.py:209:get_accelerator] Setting accelerator to CPU. If you have GPU or other accelerator, we were unable to detect it.\n",
      "[2025-07-28 14:39:56,463] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cpu (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/soehrle/envs/satvis_kernel/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-07-28 14:40:06,872] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('/explore/nobackup/people/jacaraba/development/satvision-pix4d')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*cuda capability 7.0.*\")\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from satvision_pix4d.configs.config import _C, _update_config_from_file\n",
    "from satvision_pix4d.utils import get_strategy, get_distributed_train_batches\n",
    "from satvision_pix4d.pipelines import PIPELINES, get_available_pipelines\n",
    "from satvision_pix4d.datamodules import DATAMODULES, get_available_datamodules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20582f44-8305-451f-add0-9cf1dc7fd4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = '/explore/nobackup/projects/pix4dcloud/jacaraba/model_development/satmae/' + \\\n",
    "    'satmae_satvision_pix4d_pretrain-dev/satmae_satvision_pix4d_pretrain-dev/epoch-epoch=0.ckpt/checkpoint/mp_rank_00_model_states.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83bb0e8e-22e8-4e77-989e-9a0e73b3d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_filename = '/explore/nobackup/people/jacaraba/development/satvision-pix4d/tests/configs/test_satmae_dev.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5177cf-15f7-4f3a-90c9-d83869a54af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = _C.clone()\n",
    "_update_config_from_file(config, config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d782e136-7fab-4a8a-9d6d-f19bdf633785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import argparse\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\".*cuda capability 7.0.*\")\n",
    "\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "from satvision_pix4d.configs.config import _C, _update_config_from_file\n",
    "from satvision_pix4d.utils import get_strategy, get_distributed_train_batches\n",
    "from satvision_pix4d.pipelines import PIPELINES, get_available_pipelines\n",
    "from satvision_pix4d.datamodules import DATAMODULES, get_available_datamodules\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# main\n",
    "# -----------------------------------------------------------------------------\n",
    "def main(config, output_dir):\n",
    "\n",
    "    logging.info('Training')\n",
    "\n",
    "    # Save configuration path to disk\n",
    "    path = os.path.join(\n",
    "        output_dir,\n",
    "        f\"{config.TAG}.config.json\"\n",
    "    )\n",
    "\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(config.dump())\n",
    "\n",
    "    logging.info(f\"Full config saved to {path}\")\n",
    "    logging.info(config.dump())\n",
    "\n",
    "    # Get the proper pipeline\n",
    "    available_pipelines = get_available_pipelines()\n",
    "    logging.info(\"Available pipelines:\", available_pipelines)\n",
    "\n",
    "    pipeline = PIPELINES[config.PIPELINE]\n",
    "    logging.info(f'Using {pipeline}')\n",
    "\n",
    "    ptlPipeline = pipeline(config)\n",
    "\n",
    "    # Resume from checkpoint\n",
    "    if config.MODEL.RESUME:\n",
    "        logging.info(\n",
    "            f'Attempting to resume from checkpoint {config.MODEL.RESUME}')\n",
    "        ptlPipeline = pipeline.load_from_checkpoint(config.MODEL.RESUME)\n",
    "\n",
    "    # Determine training strategy\n",
    "    strategy = get_strategy(config)\n",
    "\n",
    "    # Define core callbacks\n",
    "    checkpoint_best = ModelCheckpoint(\n",
    "        dirpath=output_dir,\n",
    "        monitor=\"val_loss\",\n",
    "        mode=\"min\",\n",
    "        save_top_k=3,\n",
    "        filename=\"best-{epoch}-{val_loss:.4f}\",\n",
    "    )\n",
    "    checkpoint_periodic = ModelCheckpoint(\n",
    "        dirpath=output_dir,\n",
    "        every_n_epochs=1,\n",
    "        save_top_k=-1,   # Save all checkpoints at the specified interval\n",
    "        filename=\"epoch-{epoch}\",\n",
    "        save_last=True\n",
    "    )\n",
    "    lr_monitor_cb = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "    # MLflow logger\n",
    "    mlflow_logger = MLFlowLogger(\n",
    "        experiment_name=config.TAG,\n",
    "        # tracking_uri=\"file://\" + os.path.abspath(config.OUTPUT),\n",
    "        tracking_uri=\"file:///explore/nobackup/projects/pix4dcloud/mlruns\",\n",
    "        tags={\n",
    "            \"Model\": config.MODEL.NAME,\n",
    "            \"Pipeline\": config.PIPELINE,\n",
    "            \"Notes\": config.DESCRIPTION if hasattr(config, \"DESCRIPTION\") else \"\",\n",
    "        }\n",
    "    )\n",
    "    mlflow_logger.experiment.log_artifact(\n",
    "        mlflow_logger.run_id,\n",
    "        path\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        accelerator=config.TRAIN.ACCELERATOR,\n",
    "        devices=torch.cuda.device_count(),\n",
    "        strategy=strategy,\n",
    "        precision=config.PRECISION,\n",
    "        max_epochs=config.TRAIN.EPOCHS,\n",
    "        gradient_clip_val=1.0,\n",
    "        # accumulate_grad_batches=getattr(config.TRAIN, \"ACCUM_ITER\", 1),  # If you have gradient accumulation\n",
    "        log_every_n_steps=config.PRINT_FREQ,\n",
    "        default_root_dir=output_dir,\n",
    "        callbacks=[\n",
    "            checkpoint_best,\n",
    "            checkpoint_periodic,\n",
    "            lr_monitor_cb\n",
    "        ],\n",
    "        logger=mlflow_logger\n",
    "    )\n",
    "\n",
    "    # limit the number of train batches for debugging\n",
    "    if config.TRAIN.LIMIT_TRAIN_BATCHES:\n",
    "        trainer.limit_train_batches = get_distributed_train_batches(\n",
    "            config, trainer)\n",
    "\n",
    "    # setup datamodule\n",
    "    if config.DATA.DATAMODULE:\n",
    "        available_datamodules = get_available_datamodules()\n",
    "        logging.info(f\"Available data modules: {available_datamodules}\")\n",
    "        datamoduleClass = DATAMODULES[config.DATAMODULE]\n",
    "        datamodule = datamoduleClass(config)\n",
    "        logging.info(f'Training using datamodule: {config.DATAMODULE}')\n",
    "        \n",
    "        trainer.fit(model=ptlPipeline, datamodule=datamodule)\n",
    "\n",
    "        # quick test of datamodule\n",
    "        #datamodule.setup(stage=None)\n",
    "        #print(\"Train dataset size:\", len(datamodule.trainset))\n",
    "        #print(\"Validation dataset size:\", len(datamodule.validset))\n",
    "\n",
    "        #sample = datamodule.trainset[0]\n",
    "        #print(\"Sample type:\", type(sample))\n",
    "\n",
    "        # If your dataset returns a tuple\n",
    "        #if isinstance(sample, tuple):\n",
    "        #    x, y = sample\n",
    "        #    print(\"x shape:\", x.shape)\n",
    "        #    print(\"y shape:\", y.shape)\n",
    "\n",
    "    else:\n",
    "        logging.info(\n",
    "            'Training without datamodule, assuming data is set' +\n",
    "            f' in pipeline: {ptlPipeline}')\n",
    "        trainer.fit(model=ptlPipeline)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdc3f8-0756-42e6-8237-fd80f7a912a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
